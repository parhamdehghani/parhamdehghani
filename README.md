# Hi there 👋 I'm **Parham Dehghani**

<p align="center">
  <b>Machine Learning Engineer | Data Scientist | Particle Physicist</b><br/>
  <i>Turning cutting‑edge research into scalable, production‑grade AI.</i>
</p>

<p align="center">
  <a href="https://parhamdehghani.github.io/Portfolio/"><img src="https://img.shields.io/badge/Portfolio-%F0%9F%93%8A-green?style=flat&logo=docusign" alt="Portfolio"/></a>
  <a href="https://www.linkedin.com/in/parhamdehghani/"><img src="https://img.shields.io/badge/LinkedIn-0072b1?style=flat&logo=linkedin&logoColor=white" alt="LinkedIn"/></a>
  <a href="https://drive.google.com/file/d/1M1BD8U5_8J9uDIRhQCaQlxXKwPQ321Ky/view?usp=sharing"><img src="https://img.shields.io/badge/Certificate-Udacity%20ML%20Nanodegree-blue?style=flat&logo=Udacity" alt="Udacity ML Nanodegree"/></a>
  <a href="mailto:parham.dehghani88@gmail.com"><img src="https://img.shields.io/badge/Email-%F0%9F%93%A7-lightgrey?style=flat" alt="Email"/></a>
</p>



## 🚀 About Me

* **Machine Learning Engineer** with a background in computational particle physics, specializing in model training/evaluation, deployment,  and production systems.
* **PhD in High Energy Physics** with collider phenomenology specialization, applying advanced ML algorithms to Beyond‑Standard‑Model (BSM) searches at present and future colliders.
* Specialize in **AI development** and **LLM evaluation & fine‑tuning** (SFT & RLHF) across text, image, video & audio.
* Proficient to build MLOps pipelines with **Docker · Kubernetes · Airflow · MLflow · GitHub Actions/Jenkins** on **AWS SageMaker** & **GCP Vertex AI**.
* Passionate about bridging **HPC ↔ Cloud** and **Research ↔ Production**.

## 📚 Publications

Find my peer‑reviewed HEP papers on [Inspire‑HEP](https://inspirehep.net/authors/1809580) & [Google Scholar](https://scholar.google.ca/citations?user=uZlG1Z8AAAAJ&hl).  

## 🛠️ Tech Stack

| Category | Tooling |
| --- | --- |
| **Languages** | Python · SQL · Bash · C++/Fortran (HPC) |
| **Frameworks** | PyTorch · TensorFlow · scikit‑learn · Hugging Face 🤗 · LangChain |
| **MLOps / Infra** | Docker · Kubernetes · Airflow · MLflow · DVC · GitHub Actions · Jenkins · Prometheus + Grafana |
| **Cloud** | AWS (SageMaker, Lambda, S3) · GCP (Vertex AI, Cloud Run, BigQuery) |
| **Data Processing** | PySpark · Dask · Pandas · CUDA |

<p align="center">
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="Python" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pandas/pandas-original.svg" alt="Pandas" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/jupyter/jupyter-original.svg" alt="Jupyter" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pytorch/pytorch-original.svg" alt="PyTorch" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/tensorflow/tensorflow-original.svg" alt="TensorFlow" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/huggingface.svg" alt="Hugging Face" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/scikitlearn/scikitlearn-original.svg" alt="Scikit‑learn" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/apachespark/apachespark-original.svg" alt="Apache Spark" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original.svg" alt="Docker" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/kubernetes/kubernetes-plain.svg" alt="Kubernetes" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/amazonwebservices/amazonwebservices-original-wordmark.svg" alt="AWS" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/googlecloud/googlecloud-original.svg" alt="GCP" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/apacheairflow/apacheairflow-original.svg" alt="Airflow" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/fastapi/fastapi-original.svg" alt="FastAPI" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/git/git-original.svg" alt="Git" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/github/github-original.svg" alt="GitHub" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/postgresql/postgresql-original.svg" alt="PostgreSQL" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/streamlit/streamlit-original.svg" alt="Streamlit" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/ubuntu/ubuntu-plain.svg" alt="Ubuntu" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/mlflow.svg" alt="MLflow" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/githubactions/githubactions-original.svg" alt="GitHub Actions" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/langchain.svg" alt="LangChain" width="50" height="50"/>
</p>



## 🌐 Featured Projects

| Project | What it does | Stack | Quick Links |
| --- | --- | --- | --- |
|**scientific-multi-agent-HEP**|Building and Deploying a multi-agent AI system on AWS to automate scientific literature reviews using a fine-tuned LLM.| AWS SageMaker, S3, Docker, GitHub Actions, Hugging Face (QLoRA), RAG, PyTorch, CrewAI, FastAPI, Vector DB| [Repo](https://github.com/parhamdehghani/scientific-multi-agent-HEP), Ongoing project|
| **churn-prediction-mlops-pipeline** | Deployed scalable MLOps churn prediction system on GCP based on KKBox dataset. | DVC, MLflow, Jenkins CI/CD pipeline, Airflow, Google Kubernetes Engine (GKE), PySpark, Docker | [Repo](https://github.com/parhamdehghani/churn-prediction-mlops-pipeline), [API](https://churn-api-service-rdxj3z25yq-uc.a.run.app/predict) |
| **wanderLust-recommender-system** | Hybrid hotel recommender system on GCP that recommends hotels based on the semantic content of the input query. | Google Cloud Run, Docker, PyTorch, Fine-tuning, SVD, FastAPI | [Repo](https://github.com/parhamdehghani/WanderLust-recommender-system), [API](https://recommender-service-86763462033.northamerica-northeast1.run.app/) |
| **solar-flux-forecasting** | Forecasting daily solar F10.7 index for a 7-day horizon. | Model optimization, XGBoost, Streamlit, Unit test, Scientific report | [Repo](https://github.com/parhamdehghani/solar-flux-forecasting), [Report](https://drive.google.com/file/d/1NeYGwvV9T032_Cidss_KUKZhlRs7fapI/view?usp=sharing) |
| **detoxification‑rl** | RL‑based detoxification for LLM outputs using PPO & LoRA. | PyTorch, PEFT, Hugging Face Transformers, Reinforcement Learning | [Repo](https://github.com/parhamdehghani/detoxification-rl) |
| **WebApp_DisasterResponse** | Multi‑label crisis classifier with TF‑IDF, wrapped in a Flask web‑app. | ML-Pipeline, Flask, SVM, SQL | [Repo](https://github.com/parhamdehghani/WebApp_DisasterResponse)  |
| **Recommendation Engine** | Personalized recommendation engine using collaborative filtering and matrix factorization. | Pandas, SVD | [Repo](https://github.com/parhamdehghani/Recommendation_Engine) |
| **CovidDetectionXRay** | Detects COVID‑19 from chest X‑rays. | DenseNet201, PyTorch | [Repo](https://github.com/parhamdehghani/CovidDetectionXRay) |

> ✨ See more on my [Portfolio](https://parhamdehghani.github.io/Portfolio/).



## 🔭 Currently Working On

# scientific-multi-agent-HEP: A Multi-Agent System for Scientific Research (High Energy Physics)

**Objective:** To design, build, and deploy an end-to-end multi-agent AI system capable of automating scientific literature reviews in HEP. This project leverages a fine-tuned LLM as the "brain" for an analytical agent, all hosted within the AWS ecosystem to demonstrate production-level MLOps practices.

### **Phase 1: Data Curation & Foundation (AWS Setup)**

* **Goal:** Establish a robust data pipeline and development environment on AWS.
* **Key Activities:**
    * Develop a Python script to programmatically download research papers (metadata and PDFs) from the arXiv API.
    * Set up an **Amazon S3** bucket for raw data storage and for the final, processed fine-tuning dataset.
    * Configure **Amazon SageMaker Studio** as the primary IDE for data processing, experimentation, and script development.
    * Create a high-quality, instruction-based dataset for fine-tuning by processing raw text and generating Q&A pairs, summaries, and keyword extractions.

### **Phase 2: Specialized LLM Fine-Tuning (SageMaker)**

* **Goal:** Fine-tune an open-source LLM (e.g., Llama 3 8B or Mistral 7B) to specialize in understanding scientific language and concepts.
* **Key Activities:**
    * Implement a parameter-efficient fine-tuning (PEFT) script using **QLoRA** via the Hugging Face `transformers` and `peft` libraries.
    * Package the script and execute it as a **SageMaker Training Job** on a suitable GPU instance.
    * Evaluate the fine-tuned model against the base model on a hold-out set to measure performance improvements in scientific comprehension tasks.
    * Version and store the final model artifacts in S3.

### **Phase 3: Multi-Agent System Development (CrewAI)**

* **Goal:** Architect a collaborative team of AI agents to handle the research workflow.
* **Key Activities:**
    * Utilize the **CrewAI** framework to define three distinct agent roles:
        1.  **`Literature_Researcher`:** Queries the arXiv API to find relevant papers.
        2.  **`Research_Analyst`:** Uses the fine-tuned LLM and a **RAG (Retrieval-Augmented Generation)** pipeline with a vector database (ChromaDB/FAISS) to analyze the full text of the papers.
        3.  **`Report_Synthesizer`:** Compiles the findings into a coherent, human-readable summary.
    * Develop custom tools for the agents, such as the arXiv search function and PDF text extractor.

### **Phase 4: Integration & Productionization (Docker & SageMaker Endpoints)**

* **Goal:** Deploy the system components to create a functional, end-to-end application.
* **Key Activities:**
    * Deploy the fine-tuned model to a **SageMaker Endpoint**, creating a scalable, real-time inference API.
    * Integrate the agent system with the live SageMaker Endpoint.
    * Containerize the entire CrewAI application using **Docker** to ensure portability and reproducibility.
    * Create a CI/CD workflow using **GitHub Actions** to automate the building of the Docker container.

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=parhamdehghani&show_icons=true&hide_border=true&theme=default" alt="GitHub stats"/>
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=parhamdehghani&hide_border=true&theme=default" alt="GitHub streak"/>
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=parhamdehghani&layout=compact&hide_border=true&theme=default&hide=html" alt="Top languages"/>
</p>
<p align="center">
  <img src="https://github-profile-trophy.vercel.app/?username=parhamdehghani&theme=flat&column=8&rank=SSS,SS,S,A,B,C" alt="GitHub Trophies"/>
</p>
