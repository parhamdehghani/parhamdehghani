# Hi thereÂ ğŸ‘‹Â I'm **Parham Dehghani**

<p align="center">
  <b>Machine Learning Engineerâ€¯|â€¯Data Scientistâ€¯|â€¯Particle Physicist</b><br/>
  <i>Turning cuttingâ€‘edge research into scalable, productionâ€‘grade AI.</i>
</p>

<p align="center">
  <a href="https://parhamdehghani.github.io/Portfolio/"><img src="https://img.shields.io/badge/Portfolio-%F0%9F%93%8A-green?style=flat&logo=docusign" alt="Portfolio"/></a>
  <a href="https://www.linkedin.com/in/parhamdehghani/"><img src="https://img.shields.io/badge/LinkedIn-0072b1?style=flat&logo=linkedin&logoColor=white" alt="LinkedIn"/></a>
  <a href="https://drive.google.com/file/d/1M1BD8U5_8J9uDIRhQCaQlxXKwPQ321Ky/view?usp=sharing"><img src="https://img.shields.io/badge/Certificate-Udacity%20ML%20Nanodegree-blue?style=flat&logo=Udacity" alt="Udacity ML Nanodegree"/></a>
  <a href="mailto:parham.dehghani88@gmail.com"><img src="https://img.shields.io/badge/Email-%F0%9F%93%A7-lightgrey?style=flat" alt="Email"/></a>
</p>



## ğŸš€Â About Me

* **Machine Learning Engineer** with a background in computational particle physics, specializing in model training/evaluation, deployment,  and production systems.
* **PhD in High Energy Physics** with collider phenomenology specialization, applying advanced ML algorithms to Beyondâ€‘Standardâ€‘Model (BSM) searches at present and future colliders.
* Specialize in **AI development** and **LLM evaluation & fineâ€‘tuning** (SFTÂ &Â RLHF) across text, image, video & audio.
* Proficient to build MLOps pipelines with **Docker Â· Kubernetes Â· Airflow Â· MLflow Â· GitHub Actions/Jenkins** on **AWSâ€¯SageMaker** & **GCPâ€¯VertexÂ AI**.
* Passionate about bridging **HPC â†”Â Cloud** and **Research â†”Â Production**.

## ğŸ“šÂ Publications

Find my peerâ€‘reviewed HEP papers onÂ [Inspireâ€‘HEP](https://inspirehep.net/authors/1809580)Â &Â [GoogleÂ Scholar](https://scholar.google.ca/citations?user=uZlG1Z8AAAAJ&hl).  

## ğŸ› ï¸Â TechÂ Stack

| Category | Tooling |
| --- | --- |
| **Languages** | Python Â· SQL Â· Bash Â· C++/Fortran (HPC) |
| **Frameworks** | PyTorch Â· TensorFlow Â· scikitâ€‘learn Â· HuggingÂ Face ğŸ¤— Â· LangChain |
| **MLOps / Infra** | Docker Â· Kubernetes Â· Airflow Â· MLflow Â· DVC Â· GitHubÂ Actions Â· Jenkins Â· PrometheusÂ +Â Grafana |
| **Cloud** | AWSÂ (SageMaker, Lambda, S3) Â· GCPÂ (VertexÂ AI, Cloud Run, BigQuery) |
| **Data Processing** | PySpark Â· Dask Â· Pandas Â· CUDA |

<p align="center">
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="Python" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pandas/pandas-original.svg" alt="Pandas" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/jupyter/jupyter-original.svg" alt="Jupyter" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pytorch/pytorch-original.svg" alt="PyTorch" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/tensorflow/tensorflow-original.svg" alt="TensorFlow" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/huggingface.svg" alt="HuggingÂ Face" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/scikitlearn/scikitlearn-original.svg" alt="Scikitâ€‘learn" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/apachespark/apachespark-original.svg" alt="Apache Spark" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original.svg" alt="Docker" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/kubernetes/kubernetes-plain.svg" alt="Kubernetes" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/amazonwebservices/amazonwebservices-original-wordmark.svg" alt="AWS" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/googlecloud/googlecloud-original.svg" alt="GCP" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/apacheairflow/apacheairflow-original.svg" alt="Airflow" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/fastapi/fastapi-original.svg" alt="FastAPI" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/git/git-original.svg" alt="Git" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/github/github-original.svg" alt="GitHub" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/postgresql/postgresql-original.svg" alt="PostgreSQL" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/streamlit/streamlit-original.svg" alt="Streamlit" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/ubuntu/ubuntu-plain.svg" alt="Ubuntu" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/mlflow.svg" alt="MLflow" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/githubactions/githubactions-original.svg" alt="GitHub Actions" width="50" height="50"/>
  <img src="https://raw.githubusercontent.com/simple-icons/simple-icons/develop/icons/langchain.svg" alt="LangChain" width="50" height="50"/>
</p>



## ğŸŒÂ FeaturedÂ Projects

| Project | What it does | Stack | QuickÂ Links |
| --- | --- | --- | --- |
|**scientific-multi-agent-HEP**|Building and Deploying a multi-agent AI system on AWS to automate scientific literature reviews using a fine-tuned LLM.| AWS SageMaker, S3, Docker, GitHub Actions, Hugging Face (QLoRA), RAG, PyTorch, CrewAI, FastAPI, Vector DB| [Repo](https://github.com/parhamdehghani/scientific-multi-agent-HEP), Ongoing project|
| **churn-prediction-mlops-pipeline** | Deployed scalable MLOps churn prediction system on GCP based on KKBox dataset. | DVC, MLflow, Jenkins CI/CD pipeline, Airflow, Google Kubernetes Engine (GKE), PySpark, Docker | [Repo](https://github.com/parhamdehghani/churn-prediction-mlops-pipeline), [API](https://churn-api-service-rdxj3z25yq-uc.a.run.app/predict) |
| **wanderLust-recommender-system** | Hybrid hotel recommender system on GCP that recommends hotels based on the semantic content of the input query. | Google Cloud Run, Docker, PyTorch, Fine-tuning, SVD, FastAPI | [Repo](https://github.com/parhamdehghani/WanderLust-recommender-system), [API](https://recommender-service-86763462033.northamerica-northeast1.run.app/) |
| **solar-flux-forecasting** | Forecasting daily solar F10.7 index for a 7-day horizon. | Model optimization, XGBoost, Streamlit, Unit test, Scientific report | [Repo](https://github.com/parhamdehghani/solar-flux-forecasting), [Report](https://drive.google.com/file/d/1NeYGwvV9T032_Cidss_KUKZhlRs7fapI/view?usp=sharing) |
| **detoxificationâ€‘rl** | RLâ€‘based detoxification for LLM outputs using PPO & LoRA. | PyTorch, PEFT, HuggingÂ FaceÂ Transformers, Reinforcement Learning | [Repo](https://github.com/parhamdehghani/detoxification-rl) |
| **WebApp_DisasterResponse** | Multiâ€‘label crisis classifier with TFâ€‘IDF, wrapped in a Flask webâ€‘app. | ML-Pipeline, Flask, SVM, SQL | [Repo](https://github.com/parhamdehghani/WebApp_DisasterResponse)  |
| **RecommendationÂ Engine** | Personalized recommendation engine using collaborative filtering and matrix factorization. | Pandas, SVD | [Repo](https://github.com/parhamdehghani/Recommendation_Engine) |
| **CovidDetectionXRay** | Detects COVIDâ€‘19 from chestÂ Xâ€‘rays. | DenseNet201, PyTorch | [Repo](https://github.com/parhamdehghani/CovidDetectionXRay) |

> âœ¨Â See more on myÂ [Portfolio](https://parhamdehghani.github.io/Portfolio/).



## ğŸ”­Â CurrentlyÂ WorkingÂ On

# scientific-multi-agent-HEP: A Multi-Agent System for Scientific Research (High Energy Physics)

**Objective:** To design, build, and deploy an end-to-end multi-agent AI system capable of automating scientific literature reviews in HEP. This project leverages a fine-tuned LLM as the "brain" for an analytical agent, all hosted within the AWS ecosystem to demonstrate production-level MLOps practices.

### **Phase 1: Data Curation & Foundation (AWS Setup)**

* **Goal:** Establish a robust data pipeline and development environment on AWS.
* **Key Activities:**
    * Develop a Python script to programmatically download research papers (metadata and PDFs) from the arXiv API.
    * Set up an **Amazon S3** bucket for raw data storage and for the final, processed fine-tuning dataset.
    * Configure **Amazon SageMaker Studio** as the primary IDE for data processing, experimentation, and script development.
    * Create a high-quality, instruction-based dataset for fine-tuning by processing raw text and generating Q&A pairs, summaries, and keyword extractions.

### **Phase 2: Specialized LLM Fine-Tuning (SageMaker)**

* **Goal:** Fine-tune an open-source LLM (e.g., Llama 3 8B or Mistral 7B) to specialize in understanding scientific language and concepts.
* **Key Activities:**
    * Implement a parameter-efficient fine-tuning (PEFT) script using **QLoRA** via the Hugging Face `transformers` and `peft` libraries.
    * Package the script and execute it as a **SageMaker Training Job** on a suitable GPU instance.
    * Evaluate the fine-tuned model against the base model on a hold-out set to measure performance improvements in scientific comprehension tasks.
    * Version and store the final model artifacts in S3.

### **Phase 3: Multi-Agent System Development (CrewAI)**

* **Goal:** Architect a collaborative team of AI agents to handle the research workflow.
* **Key Activities:**
    * Utilize the **CrewAI** framework to define three distinct agent roles:
        1.  **`Literature_Researcher`:** Queries the arXiv API to find relevant papers.
        2.  **`Research_Analyst`:** Uses the fine-tuned LLM and a **RAG (Retrieval-Augmented Generation)** pipeline with a vector database (ChromaDB/FAISS) to analyze the full text of the papers.
        3.  **`Report_Synthesizer`:** Compiles the findings into a coherent, human-readable summary.
    * Develop custom tools for the agents, such as the arXiv search function and PDF text extractor.

### **Phase 4: Integration & Productionization (Docker & SageMaker Endpoints)**

* **Goal:** Deploy the system components to create a functional, end-to-end application.
* **Key Activities:**
    * Deploy the fine-tuned model to a **SageMaker Endpoint**, creating a scalable, real-time inference API.
    * Integrate the agent system with the live SageMaker Endpoint.
    * Containerize the entire CrewAI application using **Docker** to ensure portability and reproducibility.
    * Create a CI/CD workflow using **GitHub Actions** to automate the building of the Docker container.

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=parhamdehghani&show_icons=true&hide_border=true&theme=default" alt="GitHubÂ stats"/>
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=parhamdehghani&hide_border=true&theme=default" alt="GitHubÂ streak"/>
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=parhamdehghani&layout=compact&hide_border=true&theme=default&hide=html" alt="TopÂ languages"/>
</p>
<p align="center">
  <img src="https://github-profile-trophy.vercel.app/?username=parhamdehghani&theme=flat&column=8&rank=SSS,SS,S,A,B,C" alt="GitHubÂ Trophies"/>
</p>
